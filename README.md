# Meta
Simulation of Neurons
Try to simulate metacognition of human

# Memo
Weightの更新方法

隣同士のAxonは，発火すると距離的に近いから発火しやすくなる？
indexが近いneuron同士の発火を促進する？weightをupdateする？
すると，本質的にLayerはSparseにしないといけない？

updateのタイミング，各timestepの終わりに，weightの更新をするfunctionを回す？
同じtimestepの中で，どのNeuronからどのNeuronへのweightが更新されたかを見て，近いindexのNeuron
のweightを強くする？weight同士にも関係性が必要になってしまう・・・？
うむむ，このTargetNeuronのUpdateをするときに，本来は必要ないけど余計に隣のNeuronのUpdateもしてしまう，とか？

なんにせよ，ベンチマーク的な基準がないと何もよしあしの判断ができないぞ．どうする？
画像を５種類入れた時間データを作って，時間ごとのアウトプットNeuronの活動がクラスタリングで綺麗に分離できたら
ある程度定量化できるな？うーん・・・いやクラスタリングは元のデータで綺麗に分かれてるからだめだ．なんだじゃあ．
同じ数字で違う画像を入れて，もともとのクラスタリングでは５種類になるのが，１種類になるとかすれば，
画像の統一的な区別ができている？とか，これはいいな．Neuronを通した後に性質が変わっている．

ベンチマーク的な基準を作るために，同じ数字のいくつか違う画像を用意する．
でもここまでくらいならあの本の中にすら書いてあった気がするな．